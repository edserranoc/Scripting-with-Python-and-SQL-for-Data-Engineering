{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<div style=\"background-color: lightgray; padding: 20px; color: black;\">\n",
    "<div>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/97/Coursera-Logo_600x600.svg/1024px-Coursera-Logo_600x600.svg.png\" style=\"float: right; margin-right: 30px;\" width=\"120\"/> \n",
    "<font size=\"6.5\" color=\"#0056D2\"><b>Web Scraping usind Python </b></font> <br>\n",
    "<font size=\"5.0\" color=\"#0056D2\"><b>Scripting with Python and SQL for Data Engineering </b></font> \n",
    "</div>\n",
    "<div style=\"text-align: left\">  <br>\n",
    "Edison David Serrano Cárdenas. <br>\n",
    "MSc in Applied Mathematics <br>\n",
    "CIMAT - Sede Guanajuato <br>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color=\"#0056D2\" >**Objetives**</font> \n",
    "In this module, you will learn how to efficiently extract data from the web. You will learn how to use a scraping library to read data from websites and identify and extract specific values from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Load Libraries:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from html.parser import HTMLParser\n",
    "from typing import List, Tuple, Dict, Any, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#0056D2\" >**Introduction to Web Scraping using Python**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#0056D2\" >**Keywords:**</font> Web Scraping, HTML parsing (BeatifulSoup), Unstructured data, JSON, XML, CSV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#0056D2\" >**Parsing Techniques with HTMLParser in Python**</font> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, you will use predefined HTML variables with raw content that can be parsed. Instead of requesting the data from the web, the content is already defined and available to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n",
    "<head>\n",
    "<meta charset=\"UTF-8\"/>\n",
    "<title>1992 World Junior Championships in Athletics – Men's high jump - Wikipedia</title>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, you will use predefined HTML variables with raw content that can be parsed. Instead of requesting the data from the web, the content is already defined and available to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser(HTMLParser):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.recording = False\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == \"title\":\n",
    "            self.recording = True\n",
    "        else:\n",
    "            self.recording = False\n",
    "            \n",
    "    def handle_data(self, data):\n",
    "        if self.recording:\n",
    "            print(f\"Found data for tag: {data}\")\n",
    "            self.recording = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found data for tag: 1992 World Junior Championships in Athletics – Men's high jump - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "p = Parser()\n",
    "p.feed(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color=\"#0056D2\" >**Using Scrapy and XPath in Python**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#0056D2\" >**Creating a Web Scraping Project with Scrapy in Python**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a virtual enviroment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python3 -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install scrapy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "scrapy startproject vulnerabilities\n",
    "cd vulnerabilities\n",
    "scrapy genspider cve cve.mitre.org\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " If I go into vulnerabilities and spiders and I list the contents, you will see a cve.py. That cve.py will have a very basic class with a single method called parse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#0056D2\" >**Parsing Data with XPath and Scrapy Shell**</font> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can do here is that there's a reference map, that means that every single CVE in this website has an exploit DB ID associated with it. The business requirement what we want to try to do here today is to try to parse this data out, extract this data out. \n",
    "\n",
    "**Link:** https://cve.mitre.org/data/refs/refmap/source-EXPLOIT-DB.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By using //table, it means give me every single table that you find in this document. We see the response is that it's a list with several different items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd vul\n",
    "scrappy shell https://cve.mitre.org/data/refs/refmap/source-EXPLOIT-DB.html\n",
    ">   response\n",
    ">   response.xpath('//table')\n",
    ">   response.xpath('//table')[0]    #First Table\n",
    ">   len(response.xpath('//table')[0].xpath('tr')) #How many items have the first table \n",
    ">   table = response.xpath('//table')[3]\n",
    ">   len(table.xpath('tr'))          #Returns 10719\n",
    ">   child = table.xpath('//tr')[10]\n",
    ">   child.xpath('td//text()')[0].extract()  #Returns 'EXPLOIT-DB:10180'\n",
    ">   child.xpath('td//text()')[3].extract()  #Returns 'CVE-2009-4091'\n",
    ">   for row in table.xpath('//tr'):\n",
    ">...    try:\n",
    ">...        print(row.xpath('td//text()')[0].extract())\n",
    ">...    except IndexError:\n",
    "            pass\n",
    ">   exit()\n",
    "\n",
    "scrapy crawl cve\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Script to run Scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import scrapy\n",
    "\n",
    "class CveSpider(scrapy.Spider):\n",
    "    name = \"cve\"\n",
    "    allowed_domains = [\"cve.mitre.org\"]\n",
    "    start_urls = [\"https://cve.mitre.org/data/refs/refmap/source-EXPLOIT-DB.html\"]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for child in response.xpath('//table'):\n",
    "            if len(child.xpath('tr'))>100:\n",
    "                table = child\n",
    "                break\n",
    "        for row in table.xpath('//tr'):\n",
    "            try:\n",
    "                print(row.xpath('td//text()')[0].extract())\n",
    "            except IndexError:\n",
    "                pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#0056D2\" >**Introduction to Scrapy and XPath in Python**</font> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#0056D2\" >**Keywords:**</font>\n",
    "- BeautifulSoup: A Python library for parsing HTML and extracting data.\n",
    "- CSS selectors: Patterns used to select HTML elements for scraping.\n",
    "- Scrapy: A Python web scraping framework.\n",
    "- XPath: A query language for selecting elements in XML documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#0056D2\" >**Creating a Web Scraping Project with Scrapy in Python**</font> \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
